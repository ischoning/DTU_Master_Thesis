{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b3bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from struct import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import data_utils\n",
    "from data_utils import *\n",
    "from Constants import *\n",
    "from model import Net\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, LSTM, GRU, Conv1d, Conv2d, Dropout, MaxPool2d, BatchNorm1d, BatchNorm2d, CrossEntropyLoss, MSELoss, BCELoss\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.nn.utils.weight_norm import weight_norm\n",
    "from sklearn import preprocessing\n",
    "import shap\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a764090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b033da",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adef1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randnorm(n):\n",
    "    return np.random.normal(loc = 0, scale = 1, size = n).astype('float32')\n",
    "\n",
    "# Function to get label\n",
    "def get_labels(batch):\n",
    "    #print(\"batch:\", Variable(torch.from_numpy(batch['ts']).long()))\n",
    "    return Variable(torch.from_numpy(batch['ts']).long())\n",
    "\n",
    "# Function to get input\n",
    "def get_input(batch):\n",
    "    return {'x_img': get_variable(Variable(torch.from_numpy(batch['img'])))}\n",
    "    #return {feat: Variable(torch.from_numpy(batch[feat])) for feat in FEATS}\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    predictions = torch.max(ys, 1)[1]\n",
    "    correct_prediction = torch.eq(predictions, ts)\n",
    "    return torch.mean(correct_prediction.float())\n",
    "\n",
    "def get_targets(batch):\n",
    "    #print(\"target:\", Variable(torch.from_numpy(batch['ts']).long()))\n",
    "    return Variable(torch.FloatTensor(batch['ts']).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814ad50",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "When predicting user AMPS error, each model should be specific to the individual.\n",
    "The device and participant are set in Constants.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3a4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260 1427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_csv('/data/Isabella/thesis_spring2022/NN/models/errors/error_totals.csv')\n",
    "y = pd.read_csv('/data/AMPs/tagging_data_second-round.csv')\n",
    "print(sum(x.num_errors),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9748d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the error data\n",
    "errors_ = pd.read_csv('/data/Isabella/thesis_spring2022/NN/data_prep/error-tags_full.csv', index_col=[0])\n",
    "\n",
    "errors_.loc[:, 'subID':'Track'] = errors_.loc[:, 'subID':'Track'].astype(str)\n",
    "errors_.loc[:, 'HMD'] = errors_.loc[:, 'HMD'].astype(str)\n",
    "errors_.loc[:, 'offset'] = errors_.loc[:, 'offset'].astype(bool)\n",
    "\n",
    "# Determine whether the type of error is a motor error (and not a process error)\n",
    "errors_['motor_error'] = False\n",
    "for idx, row in errors_.iterrows():\n",
    "    if row.error_type_value1=='1' or row.error_type_value2=='1' or row.error_type_value3=='1' or row.error_type_value4=='1' or row.error_type_value5=='1':\n",
    "        errors_.loc[idx, 'motor_error'] = True\n",
    "    \n",
    "errors_ = errors_[errors_.HMD==DEVICE]\n",
    "errors_ = errors_[errors_.motor_error==True]\n",
    "\n",
    "errors_.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert all(errors_['offset'] == True), \"The timestamps of tagged errors have not been adjusted.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc0bfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subID</th>\n",
       "      <th>task</th>\n",
       "      <th>Video</th>\n",
       "      <th>Track</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>errors_in_frame</th>\n",
       "      <th>time_to_prev_error</th>\n",
       "      <th>time_to_next_error</th>\n",
       "      <th>value1</th>\n",
       "      <th>error_type_value1</th>\n",
       "      <th>...</th>\n",
       "      <th>error_subtype_value4</th>\n",
       "      <th>value4b</th>\n",
       "      <th>value5</th>\n",
       "      <th>error_type_value5</th>\n",
       "      <th>error_subtype_value5</th>\n",
       "      <th>value5b</th>\n",
       "      <th>HMD</th>\n",
       "      <th>offset</th>\n",
       "      <th>Timestamp_adjusted</th>\n",
       "      <th>motor_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P5</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P5_cereal_2_merged_varjo.mp4</td>\n",
       "      <td>error frame</td>\n",
       "      <td>7.84</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>-4</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>varjo</td>\n",
       "      <td>True</td>\n",
       "      <td>8.403196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P5</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P5_cereal_2_merged_varjo.mp4</td>\n",
       "      <td>error frame</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>varjo</td>\n",
       "      <td>True</td>\n",
       "      <td>12.403196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P5</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P5_cereal_2_merged_varjo.mp4</td>\n",
       "      <td>error frame</td>\n",
       "      <td>19.36</td>\n",
       "      <td>2</td>\n",
       "      <td>7.52</td>\n",
       "      <td>-5.64</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>varjo</td>\n",
       "      <td>True</td>\n",
       "      <td>19.923196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P5</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P5_cereal_2_merged_varjo.mp4</td>\n",
       "      <td>error frame</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5.64</td>\n",
       "      <td>-7.36</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>varjo</td>\n",
       "      <td>True</td>\n",
       "      <td>25.563196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P5_cereal_2_merged_varjo.mp4</td>\n",
       "      <td>error frame</td>\n",
       "      <td>32.36</td>\n",
       "      <td>1</td>\n",
       "      <td>7.36</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>varjo</td>\n",
       "      <td>True</td>\n",
       "      <td>32.923196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subID    task                         Video        Track  Timestamp  \\\n",
       "0    P5  cereal  P5_cereal_2_merged_varjo.mp4  error frame       7.84   \n",
       "1    P5  cereal  P5_cereal_2_merged_varjo.mp4  error frame      11.84   \n",
       "2    P5  cereal  P5_cereal_2_merged_varjo.mp4  error frame      19.36   \n",
       "3    P5  cereal  P5_cereal_2_merged_varjo.mp4  error frame      25.00   \n",
       "4    P5  cereal  P5_cereal_2_merged_varjo.mp4  error frame      32.36   \n",
       "\n",
       "  errors_in_frame time_to_prev_error time_to_next_error value1  \\\n",
       "0               2                                    -4     31   \n",
       "1               1                  4              -7.52     13   \n",
       "2               2               7.52              -5.64     13   \n",
       "3               2               5.64              -7.36      6   \n",
       "4               1               7.36              -1.12      1   \n",
       "\n",
       "  error_type_value1  ... error_subtype_value4 value4b value5  \\\n",
       "0                 2  ...                                       \n",
       "1                 1  ...                                       \n",
       "2                 1  ...                                       \n",
       "3                 1  ...                                       \n",
       "4                 1  ...                                       \n",
       "\n",
       "  error_type_value5 error_subtype_value5 value5b    HMD offset  \\\n",
       "0                                                 varjo   True   \n",
       "1                                                 varjo   True   \n",
       "2                                                 varjo   True   \n",
       "3                                                 varjo   True   \n",
       "4                                                 varjo   True   \n",
       "\n",
       "  Timestamp_adjusted motor_error  \n",
       "0           8.403196        True  \n",
       "1          12.403196        True  \n",
       "2          19.923196        True  \n",
       "3          25.563196        True  \n",
       "4          32.923196        True  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e331c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the output data from event detection\n",
    "sequences = pd.read_csv('/data/Isabella/thesis_spring2022/event_detect_out_final/all_sequences_varjo.csv')\n",
    "\n",
    "#sequences.loc[(sequences.event=='sac')&(sequences.has_blink==1)] = 'blink'\n",
    "\n",
    "# Filter data for error prediction\n",
    "events_df = sequences[sequences.HMD==DEVICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b46f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all loss, noise, and other events\n",
    "events_df.drop(events_df.loc[(events_df.event=='noise')&(events_df.event=='loss')&(events_df.event=='other')].index.tolist(),inplace=True)\n",
    "\n",
    "# Reset indices\n",
    "events_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0baca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode event as index using EVENT_DICT as defined in Constants.py\n",
    "events_df['event'] = np.where(events_df.event=='fix', EVENT_DICT['fix'], np.where(events_df.event=='sac',EVENT_DICT['sac'],np.where(events_df.event=='smp',EVENT_DICT['smp'],np.where(events_df.event=='blink',EVENT_DICT['blink'],EVENT_DICT['other']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55e29de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HMD</th>\n",
       "      <th>rate</th>\n",
       "      <th>eye</th>\n",
       "      <th>task</th>\n",
       "      <th>subID</th>\n",
       "      <th>VL</th>\n",
       "      <th>event</th>\n",
       "      <th>start_i</th>\n",
       "      <th>end_i</th>\n",
       "      <th>start_s</th>\n",
       "      <th>...</th>\n",
       "      <th>calculus_error</th>\n",
       "      <th>carpenter_error</th>\n",
       "      <th>P_nonfix</th>\n",
       "      <th>P_fix</th>\n",
       "      <th>P_ff</th>\n",
       "      <th>P_smp</th>\n",
       "      <th>P_sac</th>\n",
       "      <th>P_blink</th>\n",
       "      <th>has_blink</th>\n",
       "      <th>UID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>varjo</td>\n",
       "      <td>200</td>\n",
       "      <td>right</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P19</td>\n",
       "      <td>CVL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.081565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366132</td>\n",
       "      <td>1.527210</td>\n",
       "      <td>0.534494</td>\n",
       "      <td>0.465506</td>\n",
       "      <td>5.470863e-11</td>\n",
       "      <td>0.465506</td>\n",
       "      <td>0.384207</td>\n",
       "      <td>0.150287</td>\n",
       "      <td>0</td>\n",
       "      <td>varjoP19cerealright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>varjo</td>\n",
       "      <td>200</td>\n",
       "      <td>right</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P19</td>\n",
       "      <td>CVL</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>1.211610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230767</td>\n",
       "      <td>2.684010</td>\n",
       "      <td>0.059622</td>\n",
       "      <td>0.940378</td>\n",
       "      <td>8.531830e-01</td>\n",
       "      <td>0.087195</td>\n",
       "      <td>0.057516</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0</td>\n",
       "      <td>varjoP19cerealright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>varjo</td>\n",
       "      <td>200</td>\n",
       "      <td>right</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P19</td>\n",
       "      <td>CVL</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>1.326648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732365</td>\n",
       "      <td>0.474248</td>\n",
       "      <td>0.728794</td>\n",
       "      <td>0.271206</td>\n",
       "      <td>2.022088e-01</td>\n",
       "      <td>0.068997</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.728398</td>\n",
       "      <td>0</td>\n",
       "      <td>varjoP19cerealright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>varjo</td>\n",
       "      <td>200</td>\n",
       "      <td>right</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P19</td>\n",
       "      <td>CVL</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>1.361658</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667140</td>\n",
       "      <td>0.332860</td>\n",
       "      <td>3.218246e-01</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>varjoP19cerealright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>varjo</td>\n",
       "      <td>200</td>\n",
       "      <td>right</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P19</td>\n",
       "      <td>CVL</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>205</td>\n",
       "      <td>1.381670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913183</td>\n",
       "      <td>24.923594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>varjoP19cerealright</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HMD  rate    eye    task subID   VL  event  start_i  end_i   start_s  \\\n",
       "0  varjo   200  right  cereal   P19  CVL      2        0     25  1.081565   \n",
       "1  varjo   200  right  cereal   P19  CVL      0       26     49  1.211610   \n",
       "2  varjo   200  right  cereal   P19  CVL      1       50     56  1.326648   \n",
       "3  varjo   200  right  cereal   P19  CVL      4       57     59  1.361658   \n",
       "4  varjo   200  right  cereal   P19  CVL      0       60    205  1.381670   \n",
       "\n",
       "   ...  calculus_error  carpenter_error  P_nonfix     P_fix          P_ff  \\\n",
       "0  ...        0.366132         1.527210  0.534494  0.465506  5.470863e-11   \n",
       "1  ...        0.230767         2.684010  0.059622  0.940378  8.531830e-01   \n",
       "2  ...        0.732365         0.474248  0.728794  0.271206  2.022088e-01   \n",
       "3  ...             NaN              NaN  0.667140  0.332860  3.218246e-01   \n",
       "4  ...        0.913183        24.923594       NaN       NaN           NaN   \n",
       "\n",
       "      P_smp     P_sac   P_blink  has_blink                  UID  \n",
       "0  0.465506  0.384207  0.150287          0  varjoP19cerealright  \n",
       "1  0.087195  0.057516  0.002106          0  varjoP19cerealright  \n",
       "2  0.068997  0.000396  0.728398          0  varjoP19cerealright  \n",
       "3  0.011035  0.000000  0.000000          0  varjoP19cerealright  \n",
       "4       NaN       NaN       NaN          0  varjoP19cerealright  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df = events_df.loc[:,'HMD':]\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c757e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the experiment start and end times\n",
    "offsets = pd.read_csv('/data/Isabella/thesis_spring2022/NN/data_prep/offsets.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b5092b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HMD</th>\n",
       "      <th>subID</th>\n",
       "      <th>task</th>\n",
       "      <th>exper_start(s)</th>\n",
       "      <th>exper_end(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>varjo</td>\n",
       "      <td>P14</td>\n",
       "      <td>cereal</td>\n",
       "      <td>2.262060</td>\n",
       "      <td>175.435060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>varjo</td>\n",
       "      <td>P14</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>-0.044110</td>\n",
       "      <td>502.057489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>varjo</td>\n",
       "      <td>P23</td>\n",
       "      <td>cereal</td>\n",
       "      <td>0.794094</td>\n",
       "      <td>189.215660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>varjo</td>\n",
       "      <td>P23</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>1.659792</td>\n",
       "      <td>948.839357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>varjo</td>\n",
       "      <td>P19</td>\n",
       "      <td>cereal</td>\n",
       "      <td>2.963828</td>\n",
       "      <td>137.798528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HMD subID      task  exper_start(s)  exper_end(s)\n",
       "0  varjo   P14    cereal        2.262060    175.435060\n",
       "1  varjo   P14  sandwich       -0.044110    502.057489\n",
       "2  varjo   P23    cereal        0.794094    189.215660\n",
       "3  varjo   P23  sandwich        1.659792    948.839357\n",
       "4  varjo   P19    cereal        2.963828    137.798528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9996e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HMD</th>\n",
       "      <th>task</th>\n",
       "      <th>subID</th>\n",
       "      <th>type</th>\n",
       "      <th>lum_path</th>\n",
       "      <th>dur(s)</th>\n",
       "      <th>min_lum_roc</th>\n",
       "      <th>min_lum_frame</th>\n",
       "      <th>min_lum_time(s)</th>\n",
       "      <th>data_dur(s)</th>\n",
       "      <th>diff(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>varjo</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P14</td>\n",
       "      <td>full</td>\n",
       "      <td>/data/AMPs/second-round/avg-lum-per-frame/P14_...</td>\n",
       "      <td>172.733166</td>\n",
       "      <td>-0.621721</td>\n",
       "      <td>206.0</td>\n",
       "      <td>6.866660</td>\n",
       "      <td>172.757628</td>\n",
       "      <td>-0.024462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>varjo</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P23</td>\n",
       "      <td>full</td>\n",
       "      <td>/data/AMPs/second-round/avg-lum-per-frame/P23_...</td>\n",
       "      <td>188.033152</td>\n",
       "      <td>-0.459796</td>\n",
       "      <td>201.0</td>\n",
       "      <td>6.699994</td>\n",
       "      <td>188.056043</td>\n",
       "      <td>-0.022891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>varjo</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P19</td>\n",
       "      <td>full</td>\n",
       "      <td>/data/AMPs/second-round/avg-lum-per-frame/P19_...</td>\n",
       "      <td>137.433200</td>\n",
       "      <td>-0.376091</td>\n",
       "      <td>174.0</td>\n",
       "      <td>5.799994</td>\n",
       "      <td>137.429682</td>\n",
       "      <td>0.003519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>varjo</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P2</td>\n",
       "      <td>full</td>\n",
       "      <td>/data/AMPs/second-round/avg-lum-per-frame/P2_c...</td>\n",
       "      <td>121.699882</td>\n",
       "      <td>-0.389706</td>\n",
       "      <td>193.0</td>\n",
       "      <td>6.433327</td>\n",
       "      <td>121.715036</td>\n",
       "      <td>-0.015154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>varjo</td>\n",
       "      <td>cereal</td>\n",
       "      <td>P9</td>\n",
       "      <td>full</td>\n",
       "      <td>/data/AMPs/second-round/avg-lum-per-frame/P9_c...</td>\n",
       "      <td>123.899880</td>\n",
       "      <td>-0.535024</td>\n",
       "      <td>210.0</td>\n",
       "      <td>6.999993</td>\n",
       "      <td>123.907213</td>\n",
       "      <td>-0.007332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HMD    task subID  type  \\\n",
       "0  varjo  cereal   P14  full   \n",
       "2  varjo  cereal   P23  full   \n",
       "4  varjo  cereal   P19  full   \n",
       "6  varjo  cereal    P2  full   \n",
       "8  varjo  cereal    P9  full   \n",
       "\n",
       "                                            lum_path      dur(s)  min_lum_roc  \\\n",
       "0  /data/AMPs/second-round/avg-lum-per-frame/P14_...  172.733166    -0.621721   \n",
       "2  /data/AMPs/second-round/avg-lum-per-frame/P23_...  188.033152    -0.459796   \n",
       "4  /data/AMPs/second-round/avg-lum-per-frame/P19_...  137.433200    -0.376091   \n",
       "6  /data/AMPs/second-round/avg-lum-per-frame/P2_c...  121.699882    -0.389706   \n",
       "8  /data/AMPs/second-round/avg-lum-per-frame/P9_c...  123.899880    -0.535024   \n",
       "\n",
       "   min_lum_frame  min_lum_time(s)  data_dur(s)   diff(s)  \n",
       "0          206.0         6.866660   172.757628 -0.024462  \n",
       "2          201.0         6.699994   188.056043 -0.022891  \n",
       "4          174.0         5.799994   137.429682  0.003519  \n",
       "6          193.0         6.433327   121.715036 -0.015154  \n",
       "8          210.0         6.999993   123.907213 -0.007332  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the differences between gaze data and videos\n",
    "gaze_dur_diff = pd.read_csv('/data/Isabella/thesis_spring2022/NN/data_prep/gaze_dur_diff.csv', index_col=[0])\n",
    "gaze_dur_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906cad69",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972084fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc P19: 0.6266666730244954 [true pos = 0.6875, true neg = 0.5571428571428572]\n",
      "Test acc P24: 0.6921052603345168 [true pos = 0.5, true neg = 0.7991803278688525]\n",
      "Test acc P6: 0.6250000042574746 [true pos = 0.43609022556390975, true neg = 0.7959183673469388]\n",
      "Test acc P5: 0.7444444431198968 [true pos = 0.9044117647058824, true neg = 0.25]\n",
      "Test acc P21: 0.75 [true pos = 0.7241379310344828, true neg = 0.7741935483870968]\n",
      "Test acc P9: 0.5772727294401689 [true pos = 0.5315315315315315, true neg = 0.6238532110091743]\n",
      "Test acc P14: 0.7062499951571226 [true pos = 0.8681318681318682, true neg = 0.4927536231884058]\n",
      "Test acc P15: 0.8333333333333334 [true pos = 0.9565217391304348, true neg = 0.42857142857142855]\n",
      "Test acc P13: 0.6733333304524421 [true pos = 0.896551724137931, true neg = 0.20618556701030927]\n",
      "Test acc P18: 0.6727272786877372 [true pos = 0.7902097902097902, true neg = 0.45454545454545453]\n",
      "Test acc P25: 0.5961538495925757 [true pos = 0.3869565217391304, true neg = 0.7620689655172413]\n",
      "Test acc P22: 0.6478260813847833 [true pos = 0.8362369337979094, true neg = 0.3352601156069364]\n",
      "Test acc P23: 0.5800000021855036 [true pos = 0.4843205574912892, true neg = 0.6677316293929713]\n",
      "Test acc P3: 0.6218750011175871 [true pos = 0.7083333333333334, true neg = 0.4921875]\n",
      "Test acc P2: 1.0 [true pos = 1.0, true neg = nan]\n",
      "Test acc P8: 0.7727272727272727 [true pos = 0.622093023255814, true neg = 0.8694029850746269]\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({})\n",
    "    \n",
    "for subID in events_df.subID.unique().tolist():\n",
    "    \n",
    "    labels = []\n",
    "    features = []\n",
    "    \n",
    "    temp_ = events_df[events_df.subID == subID]\n",
    "    temp_.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    errors = errors_[errors_.subID==subID]\n",
    "    errors.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for eye in temp_.eye.unique():\n",
    "\n",
    "        success = []\n",
    "\n",
    "        for task in temp_.task.unique().tolist():\n",
    "\n",
    "            # Only include data for which there are labelled errors\n",
    "            try:\n",
    "                exper_start = offsets.loc[(offsets.subID==subID) & (offsets.task==task), 'exper_start(s)'].values[0]\n",
    "                exper_end = offsets.loc[(offsets.subID==subID) & (offsets.task==task), 'exper_end(s)'].values[0]\n",
    "                dur_diff = np.abs(gaze_dur_diff.loc[(gaze_dur_diff.subID==subID) & (gaze_dur_diff.task==task), 'diff(s)']).values[0]\n",
    "                success.append(task)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            temp = temp_.loc[(temp_.task == task) & (temp_.eye == eye)]\n",
    "            temp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            error_t = errors[errors.task==task].Timestamp_adjusted.to_numpy()\n",
    "\n",
    "            if len(error_t) == 0:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(0, len(temp)-WINDOW, STEP):\n",
    "                # Only add the sequence if it falls within the experiment time\n",
    "                if temp.loc[i, 'start_s'] < exper_start or temp.loc[i+WINDOW-1, 'end_s'] > exper_end:\n",
    "                    continue\n",
    "\n",
    "                subID = temp.loc[i,'subID']\n",
    "                VL = temp.loc[i,'VL']\n",
    "\n",
    "                # Only label as error if all events fall within 2 seconds prior of error timestamp \n",
    "                #  and 5 seconds after errors timestamp -/+ the absolute value of duration difference between\n",
    "                #  gaze video and gaze data abs(gaze_dur_diff).\n",
    "                start_seq = temp.loc[i,'start_s']-3-dur_diff\n",
    "                end_seq = temp.loc[i+WINDOW-1,'end_s']+2+dur_diff\n",
    "                has_error = [(e >= start_seq and e <= end_seq) for e in error_t]\n",
    "                error = np.any(has_error)\n",
    "\n",
    "                if len(error_t) == 0 and CLASSIFIER == 'error':\n",
    "                    continue\n",
    "\n",
    "                # Event features to include\n",
    "                event = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'event'].to_numpy())\n",
    "                duration = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'duration'].to_numpy())\n",
    "                amplitude = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'amplitude'].to_numpy())\n",
    "                dispersion = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'duration'].to_numpy())\n",
    "                avg_iss = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'avg_iss'].to_numpy())\n",
    "                max_iss = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'max_iss'].to_numpy())\n",
    "                carpenter_error = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'carpenter_error'].to_numpy())\n",
    "                calculus_error = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'calculus_error'].to_numpy())\n",
    "                has_blink = np.nan_to_num(temp.loc[i:i+WINDOW-1, 'has_blink'].to_numpy())\n",
    "                random = np.random.normal(size=(1,WINDOW)).reshape((WINDOW,))\n",
    "\n",
    "                # Sequence features to include (same across each event)\n",
    "\n",
    "                # number of blinks that occur during the sequence\n",
    "                num_blinks = [event.tolist().count(EVENT_DICT['blink'] + sum(has_blink))/WINDOW]*WINDOW # blink ratio\n",
    "\n",
    "                # number of errors that happen within time range\n",
    "                #num_errors = [sum(has_error)]*WINDOW\n",
    "\n",
    "                # time from previous error to beginning of sequence\n",
    "                prev_ = np.where(error_t < start_seq)[0]\n",
    "                if len(prev_) > 0:\n",
    "                    prev_error = [start_seq-error_t[max(prev_)]]*WINDOW\n",
    "                else:\n",
    "                    prev_error = [0.0]*WINDOW\n",
    "\n",
    "                # time to next error from end of sequence\n",
    "                next_ = np.where(error_t > end_seq)[0]\n",
    "                if len(next_) > 0:\n",
    "                    next_error = [error_t[min(next_)]-end_seq]*WINDOW\n",
    "                else:\n",
    "                    next_error = [0.0]*WINDOW\n",
    "\n",
    "                # total duration of sequence\n",
    "                total_dur = [temp.loc[i+WINDOW-1,'end_s']-temp.loc[i,'start_s']]*WINDOW\n",
    "\n",
    "                # zero the non-relevant features depending on event (all blink feats)\n",
    "                fixi = np.where(event==EVENT_DICT['fix'])[0]\n",
    "                saci = np.where(event==EVENT_DICT['sac'])[0]\n",
    "                smpi = np.where(event==EVENT_DICT['smp'])[0]\n",
    "                blinki = np.where(event==EVENT_DICT['blink'])[0]\n",
    "                duration[blinki], amplitude[blinki], dispersion[blinki], avg_iss[blinki], max_iss[blinki], carpenter_error[blinki], calculus_error[blinki] = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "                \n",
    "                # labels of shape 1 x 4\n",
    "                labels.append([subID, VL, task, error])\n",
    "                # features of shape num_feats x window_size\n",
    "                features.append(np.array([event,\n",
    "                                          duration,\n",
    "                                          amplitude,\n",
    "                                          dispersion,\n",
    "                                          avg_iss,\n",
    "                                          max_iss,\n",
    "                                          carpenter_error,\n",
    "                                          calculus_error,\n",
    "                                          #num_blinks,\n",
    "                                          prev_error,\n",
    "                                          next_error,\n",
    "                                          total_dur\n",
    "                                         ]).flatten())\n",
    "\n",
    "    avg_tot_dur = sum([features[i][-1] for i in range(len(features))])/len(features)\n",
    "\n",
    "\n",
    "    ## CREATE DATA\n",
    "    feature_headers = []\n",
    "    for feat in FEATS:\n",
    "        feature_headers += [str(feat+str(i+1)) for i in range(WINDOW)]\n",
    "    label_headers = LABELS\n",
    "\n",
    "    # Combine into one dataframe\n",
    "    Y = pd.DataFrame(data=np.array(labels), columns=label_headers)\n",
    "    X = pd.DataFrame(data=np.array(features), columns=feature_headers)\n",
    "\n",
    "    df = pd.concat([Y,X],axis=1)\n",
    "\n",
    "\n",
    "    ## SPLIT INTO TRAIN AND TEST\n",
    "    # Convert error column to boolean (1=True, 0=False)\n",
    "    df['error'] = np.where(df.error=='True',1,0)\n",
    "\n",
    "    # ensure that there are same proportion of errors in train and test\n",
    "    positive = df[df[CLASSIFIER]==True]\n",
    "    negative = df[df[CLASSIFIER]==False]\n",
    "\n",
    "    X_positive = positive.iloc[:,len(LABELS):]\n",
    "    X_negative = negative.iloc[:,len(LABELS):]\n",
    "    Y_positive = positive.loc[:,CLASSIFIER]\n",
    "    Y_negative = negative.loc[:,CLASSIFIER]\n",
    "\n",
    "    x_train1, x_test1, y_train1, y_test1 = train_test_split(X_positive, Y_positive, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "    x_train2, x_test2, y_train2, y_test2 = train_test_split(X_negative, Y_negative, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "\n",
    "    x_train = pd.concat([x_train1, x_train2], axis=0)\n",
    "    x_test = pd.concat([x_test1, x_test2], axis=0)\n",
    "    y_train = pd.concat([y_train1, y_train2], axis=0)\n",
    "    y_test = pd.concat([y_test1, y_test2], axis=0)\n",
    "\n",
    "    ## LOAD INTO DATA LOADER\n",
    "    data = load_data(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    ## CREATE BATCHES\n",
    "    dummy_batch_gen = batch_generator(data, batch_size=BATCH_SIZE, num_classes=NUM_CLASSES, num_iterations=5e3, seed=42)\n",
    "    train_batch = next(dummy_batch_gen.gen_train())\n",
    "    valid_batch, i = next(dummy_batch_gen.gen_valid())\n",
    "    test_batch, i = next(dummy_batch_gen.gen_test())\n",
    "\n",
    "    ## BUILD THE MODEL\n",
    "    net = Net()\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "\n",
    "    ## BUILD THE COST FUNCTION\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # weight_decay is equal to L2 regularization\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "\n",
    "    ## TRAIN THE MODEL\n",
    "    # Setup settings for training \n",
    "    VALIDATION_SIZE = 0.1 # 0.1 is ~ 100 samples for validation\n",
    "    log_every = 200\n",
    "    eval_every = 100\n",
    "\n",
    "    # Generate batches\n",
    "    #batch_gen = data_utils.batch_generator(data,\n",
    "    batch_gen = batch_generator(data,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               num_classes=NUM_CLASSES,\n",
    "                               num_iterations=MAX_ITER,\n",
    "                               seed=42,\n",
    "                               val_size=VALIDATION_SIZE)\n",
    "\n",
    "    # Initialize lists for training and validation\n",
    "    train_iter = []\n",
    "    train_loss, train_accs = [], []\n",
    "    valid_iter = []\n",
    "    valid_loss, valid_accs = [], []\n",
    "\n",
    "    avg_loss = []\n",
    "    avg_accs = []\n",
    "\n",
    "    # Train network\n",
    "    net.train()\n",
    "    for i, batch_train in enumerate(batch_gen.gen_train()):\n",
    "        if i % eval_every == 0:\n",
    "            # Do the validation\n",
    "            net.eval()\n",
    "            val_losses, val_accs, val_lengths = 0, 0, 0\n",
    "            for batch_valid, num in batch_gen.gen_valid():\n",
    "                if num != BATCH_SIZE:\n",
    "                    continue\n",
    "                output = net(**get_input(batch_valid))\n",
    "                labels_argmax = torch.max(get_labels(batch_valid), 1)[1]\n",
    "                val_losses += criterion(output['out'], labels_argmax) * num\n",
    "                val_accs += accuracy(output['out'], labels_argmax) * num\n",
    "                val_lengths += num\n",
    "\n",
    "            # Divide by the total accumulated batch sizes\n",
    "            val_losses /= val_lengths\n",
    "            val_accs /= val_lengths\n",
    "            valid_loss.append(get_numpy(val_losses))\n",
    "            valid_accs.append(get_numpy(val_accs))\n",
    "            valid_iter.append(i)\n",
    "    #         print(\"Valid, it: {} loss: {:.2f} accs: {:.2f}\\n\".format(i, valid_loss[-1], valid_accs[-1]))\n",
    "            net.train()\n",
    "\n",
    "        # Train network\n",
    "        output = net(**get_input(batch_train))\n",
    "        labels_argmax = torch.max(get_labels(batch_train), 1)[1]\n",
    "        batch_loss = criterion(output['out'], labels_argmax)\n",
    "\n",
    "        train_iter.append(i)\n",
    "        train_loss.append(float(get_numpy(batch_loss)))\n",
    "        train_accs.append(float(get_numpy(accuracy(output['out'], labels_argmax))))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "        # Log i figure\n",
    "        if i % log_every == 0:\n",
    "\n",
    "            #clear_output(wait=True)\n",
    "\n",
    "            avg_loss.append(np.average(train_loss))\n",
    "            avg_accs.append(np.average(train_accs))\n",
    "\n",
    "        if MAX_ITER < i:\n",
    "            break\n",
    "\n",
    "    train_loss, train_acc = avg_loss[-1], avg_accs[-1]\n",
    "\n",
    "    ## TEST THE MODEL\n",
    "    test_accs = []\n",
    "    cvl_preds, cvl_accs = [], []\n",
    "    pvl_preds, pvl_accs = [], []\n",
    "    preds, targs = [], []\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for batch_test, num in batch_gen.gen_test():\n",
    "            if num != BATCH_SIZE:\n",
    "                continue\n",
    "            output = net(**get_input(batch_test))\n",
    "            targets = torch.max(get_labels(batch_test), 1)[1]  # 1 is cvl, 0 is pvl\n",
    "            predictions = torch.max(output['out'], 1)[1]\n",
    "            pred_isCorrect = torch.eq(predictions, targets)\n",
    "            batch_acc = torch.mean(pred_isCorrect.float())\n",
    "            test_accs.append(float(batch_acc.item()))\n",
    "\n",
    "            pred_accs = torch.max(output['out'], 1)[0]\n",
    "            pred_accs = pred_accs.tolist()\n",
    "\n",
    "            # for plotting purposes\n",
    "            targets = targets.tolist()\n",
    "            predictions = predictions.tolist()\n",
    "            targs.extend(targets)\n",
    "            preds.extend(predictions)\n",
    "\n",
    "            # for results    \n",
    "            for i in range(len(targets)):\n",
    "                if targets[i] == 1:\n",
    "                    if predictions[i] == 1:\n",
    "                        cvl_preds.append(True)\n",
    "                        cvl_accs.append(pred_accs[i])\n",
    "                    else:\n",
    "                        cvl_preds.append(False)\n",
    "                elif targets[i] == 0:\n",
    "                    if predictions[i] == 0:\n",
    "                        pvl_preds.append(True)\n",
    "                        pvl_accs.append(pred_accs[i])\n",
    "                    else:\n",
    "                        pvl_preds.append(False)\n",
    "    \n",
    "    test_acc = np.average(test_accs)\n",
    "    error_true = np.average(cvl_preds) # true pos\n",
    "    no_error_true = np.average(pvl_preds) # true neg\n",
    "    error_true_accs = np.average(cvl_accs)\n",
    "    no_error_true_accs = np.average(pvl_accs)\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame({'subID':[subID],\n",
    "                                      'task':['combined'],\n",
    "                                      'avg_tot_dur':[avg_tot_dur],\n",
    "                                      'train_loss':[train_loss],\n",
    "                                      'train_acc':[train_acc],\n",
    "                                      'test_acc':[test_acc],\n",
    "                                      'error_true':[error_true],\n",
    "                                      'no_error_true':[no_error_true],\n",
    "                                      'error_true_accs':[error_true_accs],\n",
    "                                      'no_error_true_accs':[no_error_true_accs]})])\n",
    "\n",
    "    print(f'Test acc {subID}: {test_acc} [true pos = {error_true}, true neg = {no_error_true}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96259d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/data/Isabella/thesis_spring2022/NN/results_after_FI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a779cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subID</th>\n",
       "      <th>task</th>\n",
       "      <th>avg_tot_dur</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>error_true</th>\n",
       "      <th>no_error_true</th>\n",
       "      <th>error_true_accs</th>\n",
       "      <th>no_error_true_accs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P19</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.201509</td>\n",
       "      <td>0.597313</td>\n",
       "      <td>0.688820</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.962905</td>\n",
       "      <td>0.947082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P24</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.062364</td>\n",
       "      <td>0.569662</td>\n",
       "      <td>0.729490</td>\n",
       "      <td>0.692105</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.926523</td>\n",
       "      <td>0.945131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P6</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.704932</td>\n",
       "      <td>0.559025</td>\n",
       "      <td>0.736023</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.436090</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.921458</td>\n",
       "      <td>0.966606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P5</td>\n",
       "      <td>combined</td>\n",
       "      <td>8.287311</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>0.784555</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.904412</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.979514</td>\n",
       "      <td>0.982248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P21</td>\n",
       "      <td>combined</td>\n",
       "      <td>8.479499</td>\n",
       "      <td>0.357770</td>\n",
       "      <td>0.953349</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>0.965248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P9</td>\n",
       "      <td>combined</td>\n",
       "      <td>7.457047</td>\n",
       "      <td>0.550240</td>\n",
       "      <td>0.752866</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.531532</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.976538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P14</td>\n",
       "      <td>combined</td>\n",
       "      <td>7.237658</td>\n",
       "      <td>0.557704</td>\n",
       "      <td>0.750350</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.986845</td>\n",
       "      <td>0.992951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15</td>\n",
       "      <td>combined</td>\n",
       "      <td>7.027839</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.905965</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.998557</td>\n",
       "      <td>0.985639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P13</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.855649</td>\n",
       "      <td>0.576228</td>\n",
       "      <td>0.729474</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.980518</td>\n",
       "      <td>0.918382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P18</td>\n",
       "      <td>combined</td>\n",
       "      <td>7.451448</td>\n",
       "      <td>0.542691</td>\n",
       "      <td>0.758664</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.962190</td>\n",
       "      <td>0.921216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P25</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.672649</td>\n",
       "      <td>0.592497</td>\n",
       "      <td>0.699034</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.891408</td>\n",
       "      <td>0.952104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P22</td>\n",
       "      <td>combined</td>\n",
       "      <td>7.306460</td>\n",
       "      <td>0.623410</td>\n",
       "      <td>0.667311</td>\n",
       "      <td>0.647826</td>\n",
       "      <td>0.836237</td>\n",
       "      <td>0.335260</td>\n",
       "      <td>0.934882</td>\n",
       "      <td>0.882923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P23</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.511491</td>\n",
       "      <td>0.627420</td>\n",
       "      <td>0.657614</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.484321</td>\n",
       "      <td>0.667732</td>\n",
       "      <td>0.864731</td>\n",
       "      <td>0.923918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3</td>\n",
       "      <td>combined</td>\n",
       "      <td>7.780417</td>\n",
       "      <td>0.570464</td>\n",
       "      <td>0.727458</td>\n",
       "      <td>0.621875</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.948943</td>\n",
       "      <td>0.911039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>combined</td>\n",
       "      <td>6.983288</td>\n",
       "      <td>0.427086</td>\n",
       "      <td>0.886155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P8</td>\n",
       "      <td>combined</td>\n",
       "      <td>5.288483</td>\n",
       "      <td>0.557536</td>\n",
       "      <td>0.747201</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.869403</td>\n",
       "      <td>0.972524</td>\n",
       "      <td>0.980105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subID      task  avg_tot_dur  train_loss  train_acc  test_acc  error_true  \\\n",
       "0   P19  combined     6.201509    0.597313   0.688820  0.626667    0.687500   \n",
       "0   P24  combined     6.062364    0.569662   0.729490  0.692105    0.500000   \n",
       "0    P6  combined     6.704932    0.559025   0.736023  0.625000    0.436090   \n",
       "0    P5  combined     8.287311    0.527193   0.784555  0.744444    0.904412   \n",
       "0   P21  combined     8.479499    0.357770   0.953349  0.750000    0.724138   \n",
       "0    P9  combined     7.457047    0.550240   0.752866  0.577273    0.531532   \n",
       "0   P14  combined     7.237658    0.557704   0.750350  0.706250    0.868132   \n",
       "0   P15  combined     7.027839    0.406700   0.905965  0.833333    0.956522   \n",
       "0   P13  combined     6.855649    0.576228   0.729474  0.673333    0.896552   \n",
       "0   P18  combined     7.451448    0.542691   0.758664  0.672727    0.790210   \n",
       "0   P25  combined     6.672649    0.592497   0.699034  0.596154    0.386957   \n",
       "0   P22  combined     7.306460    0.623410   0.667311  0.647826    0.836237   \n",
       "0   P23  combined     6.511491    0.627420   0.657614  0.580000    0.484321   \n",
       "0    P3  combined     7.780417    0.570464   0.727458  0.621875    0.708333   \n",
       "0    P2  combined     6.983288    0.427086   0.886155  1.000000    1.000000   \n",
       "0    P8  combined     5.288483    0.557536   0.747201  0.772727    0.622093   \n",
       "\n",
       "   no_error_true  error_true_accs  no_error_true_accs  \n",
       "0       0.557143         0.962905            0.947082  \n",
       "0       0.799180         0.926523            0.945131  \n",
       "0       0.795918         0.921458            0.966606  \n",
       "0       0.250000         0.979514            0.982248  \n",
       "0       0.774194         0.997330            0.965248  \n",
       "0       0.623853         0.970370            0.976538  \n",
       "0       0.492754         0.986845            0.992951  \n",
       "0       0.428571         0.998557            0.985639  \n",
       "0       0.206186         0.980518            0.918382  \n",
       "0       0.454545         0.962190            0.921216  \n",
       "0       0.762069         0.891408            0.952104  \n",
       "0       0.335260         0.934882            0.882923  \n",
       "0       0.667732         0.864731            0.923918  \n",
       "0       0.492188         0.948943            0.911039  \n",
       "0            NaN         0.999981                 NaN  \n",
       "0       0.869403         0.972524            0.980105  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
